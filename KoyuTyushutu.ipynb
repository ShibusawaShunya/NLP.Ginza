{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KoyuTyushutu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO51l68aOjCVMO/1jhg9jj7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShibusawaShunya/NLP.Ginza/blob/main/KoyuTyushutu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxeD98weT2YL"
      },
      "outputs": [],
      "source": [
        "!pip install ginza==4.0.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#固有表現抽出\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy.load('ja_ginza')\n",
        "doc = nlp('山田さんと銀座でランチをご一緒しましょう。')\n",
        "\n",
        "for entity in doc.ents:\n",
        "  print(\n",
        "        entity.text+' , '+\n",
        "        entity.label_+' , '+\n",
        "        str(entity.start_char)+' , '+\n",
        "        str(entity.end_char))\n",
        "  \n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "4XgMQBMoT-Sb",
        "outputId": "7f359c89-6981-4d25-a374-7a8e918fbb4f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "山田 , Person , 0 , 2\n",
            "さん , Title_Other , 2 , 4\n",
            "銀座 , City , 5 , 7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    山田\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Person</span>\n",
              "</mark>\n",
              "\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    さん\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">Title_Other</span>\n",
              "</mark>\n",
              "と\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    銀座\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">City</span>\n",
              "</mark>\n",
              "でランチをご一緒しましょう。</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#固有表現抽出モデルの学習\n",
        "\n",
        "%%time\n",
        "import spacy\n",
        "import random\n",
        "\n",
        "def train_ner(train_data, epoch):\n",
        "  nlp = spacy.blank('ja')\n",
        "\n",
        "  if 'ner' not in nlp.pipe_names:\n",
        "    ner =nlp.create_pipe('ner')\n",
        "    nlp.add_pipe(ner, last=True)\n",
        "\n",
        "  for _, annotations in train_data:\n",
        "    for ent in annotations.get('entities'):\n",
        "        ner.add_label(ent[2])\n",
        "\n",
        "  other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "  with nlp.disable_pipes(*other_pipes):\n",
        "    optimizer = nlp.begin_training()\n",
        "\n",
        "    for itn in range(epoch):\n",
        "\n",
        "      random.shuffle(train_data)\n",
        "\n",
        "      losses = {}\n",
        "      for text, annotations in train_data:\n",
        "          nlp.update([text], [annotations], drop=0.2, sgd=optimizer, losses=losses)\n",
        "      print('iteration{}: {:.8f}' .format(itn, losses['ner']))\n",
        "  return nlp\n",
        "\n",
        "train_data = [\n",
        "              ('入院している母のお見舞いに行ったサツキとメイはオバケ屋敷のことを報告した。',\n",
        "               {'entities': [(16, 19, 'Person'), (20, 22, 'Perspn')]}),\n",
        "              ('サツキとメイが森のバス停で雨の中父の帰りを待っている。',\n",
        "               {'entities': [(0, 3, 'Person'), (4, 6, 'Perspn')]}),\n",
        "              ('一人で遊んでいたメイは庭で不思議な生き物を見つけた。', \n",
        "               {'entities': [(8, 10, 'Person')]}),\n",
        "              ('人が住み始めるといつのまにかいなくなるという話を聞いてサツキは拍子抜けした。',\n",
        "               {'entities': [(27, 30, 'Person')]}),\n",
        "]\n",
        "\n",
        "nlp = train_ner(train_data, 50)\n",
        "\n",
        "nlp.to_disk('ner_model')"
      ],
      "metadata": {
        "id": "oyaJ9PAuUu0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#学習データを使用した固有抽出表現\n",
        "\n",
        "doc = nlp('サツキと妹のメイは、母の療養のために父と一緒に農村へ引っ越してきた。')\n",
        "for ent in doc.ents:\n",
        "  print(\n",
        "      ent.text+' , '+\n",
        "      ent.label_+' , '+\n",
        "      str(ent.start_char)+' , '+\n",
        "      str(ent.end_char)\n",
        "  )"
      ],
      "metadata": {
        "id": "Ec9RZL2lXs0M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wikipediaを用いた固有表現抽出モデルの学習\n",
        "\n",
        "%%time\n",
        "import spacy\n",
        "import random\n",
        "\n",
        "def train_ner(train_data, epoch):\n",
        "  nlp = spacy.blank('ja')\n",
        "\n",
        "  if 'ner' not in nlp.pipe_names:\n",
        "    ner =nlp.create_pipe('ner')\n",
        "    nlp.add_pipe(ner, last=True)\n",
        "\n",
        "  for _, annotations in train_data:\n",
        "    for ent in annotations.get('entities'):\n",
        "        ner.add_label(ent[2])\n",
        "\n",
        "  other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "  with nlp.disable_pipes(*other_pipes):\n",
        "    optimizer = nlp.begin_training()\n",
        "\n",
        "    for itn in range(epoch):\n",
        "\n",
        "      random.shuffle(train_data)\n",
        "\n",
        "      losses = {}\n",
        "      for text, annotations in train_data:\n",
        "          nlp.update([text], [annotations], drop=0.2, sgd=optimizer, losses=losses)\n",
        "      print('iteration{}: {:.8f}' .format(itn, losses['ner']))\n",
        "  return nlp\n",
        "\n",
        "import json\n",
        "labels = {\n",
        "    '人名': 'Person',\n",
        "    '法人名': 'Juridical_Person',\n",
        "    '政治的組織名': 'Political_Organization',\n",
        "    'その他の組織名': 'Organization_Other',\n",
        "    '地名': 'Location',\n",
        "    '施設名': 'Facility',\n",
        "    '製品名': 'Product',\n",
        "    'イベント名': 'Event',\n",
        "}\n",
        "json_data = json.load(open('ner.json', 'r'))\n",
        "train_data = []\n",
        "for data in json_data:\n",
        "  text = data['text']\n",
        "  entities = data['entities']\n",
        "  value = []\n",
        "  for entity in entities:\n",
        "    span = entity['span']\n",
        "    label = labels[entity['type']]\n",
        "    value.append((span[0], span[1], label))\n",
        "  train_data.append((text, {'entities': value}))\n",
        "\n",
        "nlp = train_ner(train_data, 50)\n",
        "\n",
        "nlp.to_disk('ner_model')"
      ],
      "metadata": {
        "id": "ICv5NoDfgpgH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}